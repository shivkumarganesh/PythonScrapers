{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to import Data from CNN's RSS Feed?\n",
    "It's very easy to import data from any RSS Feed but for this implementation we will be focusing on CNN's RSS Feed Data. In this sample we are using the RSS feed for the political data. So lets get started.\n",
    "\n",
    "We first need to import few basic libraries like **request**, **Beautiful Soup** and **pandas**. We will be using pandas for persisting data into dataframe or csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be defining two different functions out here. **cnn_news_scrapper** function is used in order to scrape data using beautiful soup. We use `features='xml'` to parse xml that is coming through RSS feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the various attributes of the article\n",
    "def getArticles(articles):\n",
    "    all_articles = []\n",
    "    for article in articles:\n",
    "        article_title = article.find('title').text\n",
    "        article_link = article.find('link').text\n",
    "        article_published = article.find('pubDate').text\n",
    "        all_articles.append({\n",
    "            'title':article_title,\n",
    "            'link':article_link,\n",
    "            'published':article_published\n",
    "        })\n",
    "    return all_articles\n",
    "    \n",
    "# Function to invoke CNN Scrapper\n",
    "def cnn_news_scrapper(URL):\n",
    "    try:\n",
    "        r = requests.get(URL)\n",
    "        soupContent = BeautifulSoup(r.content,features='xml')\n",
    "        print('Job Succeeded returning Status Code: ', r.status_code)\n",
    "        items = soupContent.findAll('item')\n",
    "        print('Total News Content')\n",
    "        print(len(items))\n",
    "        return getArticles(soupContent.findAll('item'))\n",
    "    except Exception as e:\n",
    "        print('Scraping failed due to the below exception')\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping Process\n",
    "We will start the scraping process using the above mentioned functions. We will call it using the below mentioned URL `http://rss.cnn.com/rss/cnn_allpolitics.rss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scraping\n",
      "Job Succeeded returning Status Code:  200\n",
      "Total News Content\n",
      "30\n",
      "Finished scraping\n"
     ]
    }
   ],
   "source": [
    "print('Starting scraping')\n",
    "data = cnn_news_scrapper('http://rss.cnn.com/rss/cnn_allpolitics.rss')\n",
    "print('Finished scraping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data into the DataFrame is easy. We just need to get the variable `data` and feed it into the function for creating  a new data frame eg. `pd.DataFrame(data)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State Department to list 80% of countries as '...</td>\n",
       "      <td>http://rss.cnn.com/~r/rss/cnn_allpolitics/~3/y...</td>\n",
       "      <td>Tue, 20 Apr 2021 02:48:25 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Florida governor signs controversial 'pro-law ...</td>\n",
       "      <td>http://rss.cnn.com/~r/rss/cnn_allpolitics/~3/p...</td>\n",
       "      <td>Mon, 19 Apr 2021 23:32:56 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anti-riot laws vs. police reform as the US wai...</td>\n",
       "      <td>http://rss.cnn.com/~r/rss/cnn_allpolitics/~3/O...</td>\n",
       "      <td>Tue, 20 Apr 2021 00:01:34 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York attorney general asked to investigate...</td>\n",
       "      <td>http://rss.cnn.com/~r/rss/cnn_allpolitics/~3/Z...</td>\n",
       "      <td>Mon, 19 Apr 2021 20:42:02 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Former Vice President Walter 'Fritz' Mondale d...</td>\n",
       "      <td>http://rss.cnn.com/~r/rss/cnn_allpolitics/~3/o...</td>\n",
       "      <td>Tue, 20 Apr 2021 03:50:27 GMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  State Department to list 80% of countries as '...   \n",
       "1  Florida governor signs controversial 'pro-law ...   \n",
       "2  Anti-riot laws vs. police reform as the US wai...   \n",
       "3  New York attorney general asked to investigate...   \n",
       "4  Former Vice President Walter 'Fritz' Mondale d...   \n",
       "\n",
       "                                                link  \\\n",
       "0  http://rss.cnn.com/~r/rss/cnn_allpolitics/~3/y...   \n",
       "1  http://rss.cnn.com/~r/rss/cnn_allpolitics/~3/p...   \n",
       "2  http://rss.cnn.com/~r/rss/cnn_allpolitics/~3/O...   \n",
       "3  http://rss.cnn.com/~r/rss/cnn_allpolitics/~3/Z...   \n",
       "4  http://rss.cnn.com/~r/rss/cnn_allpolitics/~3/o...   \n",
       "\n",
       "                       published  \n",
       "0  Tue, 20 Apr 2021 02:48:25 GMT  \n",
       "1  Mon, 19 Apr 2021 23:32:56 GMT  \n",
       "2  Tue, 20 Apr 2021 00:01:34 GMT  \n",
       "3  Mon, 19 Apr 2021 20:42:02 GMT  \n",
       "4  Tue, 20 Apr 2021 03:50:27 GMT  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist data as CSV\n",
    "\n",
    "# df.to_csv('cnn_political_news.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "As you can see the way we extract data from RSS feed using BeautifulSoup is pretty similar to any other scraping implementation for BeautifulSoup. It's easy to implement and use as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
